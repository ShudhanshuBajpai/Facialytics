# Facialytics

**Real-time Facial Emotion Recognition using Vision Transformers**

---

## ðŸ“Œ Overview

Facialytics is a Python-based machine learning application that leverages Vision Transformers (ViTs) for real-time facial emotion recognition. The model classifies over five distinct emotions with an accuracy of 85%, offering robust performance even on mid-range hardware.

---

## âš™ï¸ Features

- **Emotion Classification**: Classifies 5+ emotions (e.g., Happy, Sad, Angry, Surprise, Neutral) with 85% accuracy.
- **Data Augmentation**: Processes over 10,000 facial images with techniques like rotation, zoom, and brightness normalization to enhance model robustness.
- **Real-time Inference**: Achieves webcam inference with less than 200ms latency on mid-range hardware.
- **Model Optimization**: Reduces overfitting by 30% through advanced augmentation strategies.

---

## ðŸ§ª Technologies Used

- **Machine Learning Frameworks**: TensorFlow, Keras
- **Computer Vision**: OpenCV
- **Model Architecture**: Vision Transformers (ViTs)
- **Programming Language**: Python
- **Development Tools**: Jupyter Notebook, Git, GitHub

---

## ðŸ“‚ Repository Structure
```
Facialytics/
â”œâ”€â”€ emotiondetector.h5 # Trained model weights
â”œâ”€â”€ emotiondetector.json # Model architecture
â”œâ”€â”€ realtimedetection.py # Real-time webcam inference script
â”œâ”€â”€ trainmodel.ipynb # Jupyter notebook for training the model
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ .gitignore # Git ignore file
```


---

## ðŸš€ Installation

1. Clone the repository:

 ```bash
   git clone https://github.com/ShudhanshuBajpai/Facialytics.git
   cd Facialytics
```
2. Create and activate a virtual environment:

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
```

3. Install required dependencies:

```bash
pip install -r requirements.txt
```

---

## ðŸ§ª Usage

### ðŸš€ Training the Model
Train the emotion classification model:
`jupyter notebook trainmodel.ipynb`

### ðŸŽ¥ Real-time Inference
Run real-time emotion detection via your webcam:
`python realtimedetection.py`


> âš¡ **Tip:** Make sure your webcam is connected and not used by other applications.

---

## ðŸ“ˆ Results

- **Accuracy:** 85% on a multi-class emotion dataset âœ…  
- **Latency:** <200ms for real-time webcam inference â±ï¸  
- **Overfitting Reduction:** 30% improvement using data augmentation ðŸ”„  

> ðŸ’¡ *Insight:* Data augmentation significantly improves generalization for unseen faces.

---

## ðŸ› ï¸ Future Enhancements

- Expand emotion classes to include more nuanced expressions ðŸ˜²ðŸ˜”ðŸ˜Š  
- Implement model quantization for mobile deployment ðŸ“±  
- Integrate with cloud services for scalable inference â˜ï¸  

> ðŸ”§ Contributions to these enhancements are highly encouraged!

---

## ðŸ¤ Contributing

We welcome contributions!  

- **Fork** the repository  
- **Create a new branch**  
- **Submit a pull request** with your changes  

> ðŸŒŸ Letâ€™s improve this project together!

